#!rnn.py

batch_size = 5000  # done
batching = 'sort_bin_shuffle:.64'  # done
cache_size = '0'  # done
cleanup_old_models = {'keep': [80, 120, 160, 200, 240, 280, 320, 360, 400, 440, 480], 'keep_best_n': 3, 'keep_last_n': 3}  # done
debug_print_layer_output_template = True  #done
dev = { 'class': 'MetaDataset',
  'data_map': {'classes': ('dev_hdf', 'classes'), 'data': ('dev_hdf', 'data'), 'speaker_label': ('speaker_label', 'data')},
  'datasets': { 'dev_hdf': { 'class': 'HDFDataset',
                             'files': [ '/work/asr3/luescher/hiwis/jxu/setups-data/librispeech/2022-09-06--conformer-librispeech/work/crnn/hdf/CRNNSprintDumpHDFJob.a1msy8pvUkKg/output/data.hdf']},
                'speaker_label': { 'class': 'HDFDataset',
                                   'files': ['/u/jxu/setups/librispeech/2022-09-06--conformer-librispeech/output/lbs_train_spk_label']}},
  'seq_order_control_dataset': 'dev_hdf'}
device = 'gpu'  #
gradient_noise = 0.0  # done
learning_rate = 1e-05  # done
learning_rate_control = 'constant'  # done
learning_rate_file = 'learning_rates'  # done
learning_rates = [ 2e-05,
  2.1208053691275168e-05,
  2.2416107382550338e-05,
  2.3624161073825504e-05,
  2.4832214765100674e-05,
  2.604026845637584e-05,
  2.724832214765101e-05,
  2.8456375838926177e-05,
  2.9664429530201343e-05,
  3.087248322147652e-05,
  3.208053691275168e-05,
  3.328859060402685e-05,
  3.4496644295302016e-05,
  3.570469798657718e-05,
  3.6912751677852356e-05,
  3.812080536912752e-05,
  3.932885906040269e-05,
  4.0536912751677855e-05,
  4.174496644295302e-05,
  4.2953020134228195e-05,
  4.416107382550336e-05,
  4.536912751677853e-05,
  4.65771812080537e-05,
  4.778523489932886e-05,
  4.8993288590604034e-05,
  5.02013422818792e-05,
  5.140939597315437e-05,
  5.261744966442954e-05,
  5.38255033557047e-05,
  5.503355704697987e-05,
  5.6241610738255046e-05,
  5.7449664429530206e-05,
  5.865771812080538e-05,
  5.986577181208054e-05,
  6.107382550335571e-05,
  6.228187919463089e-05,
  6.348993288590604e-05,
  6.469798657718122e-05,
  6.590604026845638e-05,
  6.711409395973155e-05,
  6.832214765100672e-05,
  6.953020134228188e-05,
  7.073825503355706e-05,
  7.194630872483222e-05,
  7.315436241610739e-05,
  7.436241610738256e-05,
  7.557046979865772e-05,
  7.67785234899329e-05,
  7.798657718120806e-05,
  7.919463087248323e-05,
  8.04026845637584e-05,
  8.161073825503356e-05,
  8.281879194630874e-05,
  8.40268456375839e-05,
  8.523489932885907e-05,
  8.644295302013424e-05,
  8.76510067114094e-05,
  8.885906040268457e-05,
  9.006711409395973e-05,
  9.127516778523491e-05,
  9.248322147651008e-05,
  9.369127516778524e-05,
  9.489932885906041e-05,
  9.610738255033557e-05,
  9.731543624161075e-05,
  9.852348993288592e-05,
  9.973154362416108e-05,
  0.00010093959731543625,
  0.00010214765100671141,
  0.00010335570469798659,
  0.00010456375838926176,
  0.00010577181208053692,
  0.00010697986577181209,
  0.00010818791946308725,
  0.00010939597315436242,
  0.0001106040268456376,
  0.00011181208053691276,
  0.00011302013422818793,
  0.0001142281879194631,
  0.00011543624161073826,
  0.00011664429530201344,
  0.0001178523489932886,
  0.00011906040268456377,
  0.00012026845637583894,
  0.0001214765100671141,
  0.00012268456375838928,
  0.00012389261744966444,
  0.00012510067114093962,
  0.00012630872483221478,
  0.00012751677852348994,
  0.00012872483221476513,
  0.0001299328859060403,
  0.00013114093959731545,
  0.00013234899328859063,
  0.0001335570469798658,
  0.00013476510067114095,
  0.0001359731543624161,
  0.0001371812080536913,
  0.00013838926174496646,
  0.00013959731543624162,
  0.0001408053691275168,
  0.00014201342281879197,
  0.00014322147651006713,
  0.00014442953020134229,
  0.00014563758389261747,
  0.00014684563758389263,
  0.0001480536912751678,
  0.00014926174496644298,
  0.00015046979865771814,
  0.0001516778523489933,
  0.00015288590604026848,
  0.00015409395973154364,
  0.0001553020134228188,
  0.00015651006711409396,
  0.00015771812080536915,
  0.0001589261744966443,
  0.00016013422818791947,
  0.00016134228187919466,
  0.00016255033557046982,
  0.00016375838926174498,
  0.00016496644295302016,
  0.00016617449664429532,
  0.00016738255033557048,
  0.00016859060402684564,
  0.00016979865771812083,
  0.000171006711409396,
  0.00017221476510067115,
  0.00017342281879194633,
  0.0001746308724832215,
  0.00017583892617449665,
  0.00017704697986577184,
  0.000178255033557047,
  0.00017946308724832216,
  0.00018067114093959735,
  0.0001818791946308725,
  0.00018308724832214767,
  0.00018429530201342283,
  0.000185503355704698,
  0.00018671140939597317,
  0.00018791946308724833,
  0.00018912751677852352,
  0.00019033557046979868,
  0.00019154362416107384,
  0.00019275167785234902,
  0.00019395973154362418,
  0.00019516778523489934,
  0.0001963758389261745,
  0.0001975838926174497,
  0.00019879194630872485,
  0.0002,
  0.0002,
  0.00019879194630872485,
  0.00019758389261744966,
  0.0001963758389261745,
  0.00019516778523489934,
  0.00019395973154362416,
  0.000192751677852349,
  0.00019154362416107384,
  0.00019033557046979868,
  0.0001891275167785235,
  0.00018791946308724833,
  0.00018671140939597317,
  0.00018550335570469799,
  0.00018429530201342283,
  0.00018308724832214767,
  0.00018187919463087248,
  0.00018067114093959732,
  0.00017946308724832216,
  0.000178255033557047,
  0.0001770469798657718,
  0.00017583892617449665,
  0.0001746308724832215,
  0.0001734228187919463,
  0.00017221476510067115,
  0.000171006711409396,
  0.0001697986577181208,
  0.00016859060402684564,
  0.00016738255033557048,
  0.0001661744966442953,
  0.00016496644295302014,
  0.00016375838926174498,
  0.00016255033557046982,
  0.00016134228187919463,
  0.00016013422818791947,
  0.0001589261744966443,
  0.00015771812080536912,
  0.00015651006711409396,
  0.0001553020134228188,
  0.00015409395973154364,
  0.00015288590604026846,
  0.0001516778523489933,
  0.0001504697986577181,
  0.00014926174496644295,
  0.0001480536912751678,
  0.00014684563758389263,
  0.00014563758389261744,
  0.00014442953020134229,
  0.00014322147651006713,
  0.00014201342281879194,
  0.00014080536912751678,
  0.00013959731543624162,
  0.00013838926174496646,
  0.00013718120805369127,
  0.0001359731543624161,
  0.00013476510067114093,
  0.00013355704697986577,
  0.0001323489932885906,
  0.00013114093959731545,
  0.0001299328859060403,
  0.0001287248322147651,
  0.00012751677852348991,
  0.00012630872483221475,
  0.0001251006711409396,
  0.00012389261744966444,
  0.00012268456375838928,
  0.00012147651006711409,
  0.00012026845637583893,
  0.00011906040268456376,
  0.0001178523489932886,
  0.00011664429530201342,
  0.00011543624161073825,
  0.00011422818791946309,
  0.00011302013422818792,
  0.00011181208053691276,
  0.00011060402684563758,
  0.00010939597315436241,
  0.00010818791946308725,
  0.00010697986577181208,
  0.0001057718120805369,
  0.00010456375838926174,
  0.00010335570469798657,
  0.00010214765100671141,
  0.00010093959731543624,
  9.973154362416107e-05,
  9.85234899328859e-05,
  9.731543624161073e-05,
  9.610738255033557e-05,
  9.48993288590604e-05,
  9.369127516778523e-05,
  9.248322147651007e-05,
  9.12751677852349e-05,
  9.006711409395973e-05,
  8.885906040268456e-05,
  8.765100671140939e-05,
  8.644295302013423e-05,
  8.523489932885905e-05,
  8.40268456375839e-05,
  8.281879194630872e-05,
  8.161073825503355e-05,
  8.040268456375839e-05,
  7.919463087248322e-05,
  7.798657718120804e-05,
  7.677852348993288e-05,
  7.557046979865772e-05,
  7.436241610738254e-05,
  7.315436241610738e-05,
  7.194630872483222e-05,
  7.073825503355703e-05,
  6.953020134228187e-05,
  6.832214765100671e-05,
  6.711409395973152e-05,
  6.590604026845636e-05,
  6.46979865771812e-05,
  6.348993288590604e-05,
  6.228187919463086e-05,
  6.10738255033557e-05,
  5.986577181208054e-05,
  5.865771812080535e-05,
  5.744966442953019e-05,
  5.624161073825503e-05,
  5.5033557046979846e-05,
  5.3825503355704686e-05,
  5.2617449664429526e-05,
  5.140939597315437e-05,
  5.020134228187918e-05,
  4.899328859060402e-05,
  4.778523489932886e-05,
  4.6577181208053674e-05,
  4.5369127516778514e-05,
  4.4161073825503354e-05,
  4.295302013422817e-05,
  4.174496644295301e-05,
  4.053691275167785e-05,
  3.932885906040266e-05,
  3.81208053691275e-05,
  3.691275167785234e-05,
  3.570469798657718e-05,
  3.4496644295301996e-05,
  3.3288590604026836e-05,
  3.2080536912751676e-05,
  3.087248322147649e-05,
  2.966442953020133e-05,
  2.845637583892617e-05,
  2.7248322147650983e-05,
  2.6040268456375824e-05,
  2.4832214765100664e-05,
  2.3624161073825504e-05,
  2.2416107382550318e-05,
  2.1208053691275158e-05,
  2e-05,
  2e-05,
  1.979808080808081e-05,
  1.959616161616162e-05,
  1.9394242424242425e-05,
  1.9192323232323233e-05,
  1.8990404040404042e-05,
  1.878848484848485e-05,
  1.858656565656566e-05,
  1.8384646464646465e-05,
  1.8182727272727274e-05,
  1.7980808080808083e-05,
  1.777888888888889e-05,
  1.7576969696969697e-05,
  1.7375050505050505e-05,
  1.7173131313131314e-05,
  1.6971212121212123e-05,
  1.6769292929292932e-05,
  1.6567373737373737e-05,
  1.6365454545454546e-05,
  1.6163535353535355e-05,
  1.5961616161616163e-05,
  1.5759696969696972e-05,
  1.5557777777777778e-05,
  1.5355858585858586e-05,
  1.5153939393939395e-05,
  1.4952020202020204e-05,
  1.4750101010101013e-05,
  1.454818181818182e-05,
  1.4346262626262627e-05,
  1.4144343434343435e-05,
  1.3942424242424244e-05,
  1.3740505050505053e-05,
  1.353858585858586e-05,
  1.3336666666666667e-05,
  1.3134747474747476e-05,
  1.2932828282828285e-05,
  1.2730909090909093e-05,
  1.25289898989899e-05,
  1.232707070707071e-05,
  1.2125151515151516e-05,
  1.1923232323232325e-05,
  1.1721313131313132e-05,
  1.1519393939393941e-05,
  1.131747474747475e-05,
  1.1115555555555557e-05,
  1.0913636363636366e-05,
  1.0711717171717173e-05,
  1.0509797979797981e-05,
  1.0307878787878788e-05,
  1.0105959595959597e-05,
  9.904040404040406e-06,
  9.702121212121213e-06,
  9.500202020202022e-06,
  9.298282828282829e-06,
  9.096363636363638e-06,
  8.894444444444446e-06,
  8.692525252525254e-06,
  8.490606060606062e-06,
  8.28868686868687e-06,
  8.086767676767678e-06,
  7.884848484848487e-06,
  7.682929292929294e-06,
  7.481010101010103e-06,
  7.27909090909091e-06,
  7.0771717171717185e-06,
  6.875252525252527e-06,
  6.673333333333334e-06,
  6.471414141414143e-06,
  6.26949494949495e-06,
  6.067575757575759e-06,
  5.865656565656568e-06,
  5.663737373737375e-06,
  5.461818181818184e-06,
  5.259898989898991e-06,
  5.057979797979799e-06,
  4.856060606060608e-06,
  4.654141414141417e-06,
  4.452222222222222e-06,
  4.250303030303031e-06,
  4.04838383838384e-06,
  3.846464646464649e-06,
  3.6445454545454574e-06,
  3.4426262626262628e-06,
  3.2407070707070715e-06,
  3.0387878787878803e-06,
  2.836868686868689e-06,
  2.634949494949498e-06,
  2.433030303030303e-06,
  2.231111111111112e-06,
  2.0291919191919207e-06,
  1.8272727272727295e-06,
  1.6253535353535383e-06,
  1.4234343434343436e-06,
  1.2215151515151524e-06,
  1.0195959595959612e-06,
  8.176767676767699e-07,
  6.157575757575753e-07,
  4.1383838383838407e-07,
  2.1191919191919283e-07,
  1e-08]  # done
log = ['./crnn.log']  # done
log_batch_size = True  # done
log_verbosity = 4  # done
min_learning_rate = 1e-05  # done
model = '/u/jxu/setups/librispeech/2022-09-06--conformer-librispeech/work/jxu/crnn/sprint_training_meta/CRNNSprintTrainingMetaDatasetJob.bgnuj9fHFEK0/output/models/epoch'  # done
multiprocessing = True  # done
nadam = True  # done
network = { 'concat_reconstruct_btn': {'class': 'copy', 'from': ['tdnn_5_ff', 'reconstruct_bnt']},
  'output': { 'class': 'softmax',
              'dropout': 0.0,
              'from': 'tdnn_7_ff',
              'loss': 'ce',
              'loss_opts': {},
              'loss_scale': 1,
              'target': 'speaker_label_notime'},
  'reconstruct_bnt': { 'activation': 'tanh',
                       'class': 'linear',
                       'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                       'from': 'tdnn_5_ff_dropout',
                       'n_out': 50,
                       'with_bias': True},
  'reconstruct_output': { 'activation': 'tanh',
                          'class': 'linear',
                          'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                          'from': 'reconstruct_bnt',
                          'loss': 'mse',
                          'loss_scale': 5,
                          'n_out': 50,
                          'target': 'data',
                          'trainable': True,
                          'with_bias': True},
  'speaker_label_notime': {'axis': 'T', 'class': 'squeeze', 'from': ['data:speaker_label'], 'register_as_extern_data': 'speaker_label_notime'},
  'tdnn_1': { 'activation': 'relu',
              'batch_norm': True,
              'class': 'conv',
              'dilation_rate': 1,
              'dropout': 0.1,
              'filter_size': (3,),
              'from': 'data',
              'n_out': 512,
              'padding': 'same',
              'strides': 1,
              'trainable': True,
              'with_bias': True},
  'tdnn_2': { 'activation': 'relu',
              'batch_norm': True,
              'class': 'conv',
              'dilation_rate': 2,
              'dropout': 0.1,
              'filter_size': (3,),
              'from': 'tdnn_1',
              'n_out': 512,
              'padding': 'same',
              'strides': 1,
              'trainable': True,
              'with_bias': True},
  'tdnn_3': { 'activation': 'relu',
              'batch_norm': True,
              'class': 'conv',
              'dilation_rate': 3,
              'dropout': 0.1,
              'filter_size': (3,),
              'from': 'tdnn_2',
              'n_out': 512,
              'padding': 'same',
              'strides': 1,
              'trainable': True,
              'with_bias': True},
  'tdnn_4_ff': { 'activation': 'tanh',
                 'class': 'linear',
                 'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                 'from': 'tdnn_3',
                 'n_out': 512,
                 'trainable': True,
                 'with_bias': True},
  'tdnn_5_ff': { 'activation': 'tanh',
                 'class': 'linear',
                 'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                 'from': 'tdnn_4_ff',
                 'n_out': 1500,
                 'trainable': True,
                 'with_bias': True},
  'tdnn_5_ff_dropout': {'class': 'copy', 'dropout': None, 'from': 'tdnn_5_ff'},
  'tdnn_6': {'class': 'copy', 'from': ['tdnn_6_att_mu', 'tdnn_6_att_delta'], 'trainable': True},
  'tdnn_6_att_delta': { 'class': 'eval',
                        'eval': 'tf.math.sqrt(tf.clip_by_value(source(0)-source(1)*source(1), clip_value_min=1e-31, clip_value_max=1e7))',
                        'from': ['tdnn_6_att_weighted_x_2_merged', 'tdnn_6_att_mu'],
                        'trainable': True},
  'tdnn_6_att_e': { 'activation': None,
                    'class': 'linear',
                    'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                    'from': 'tdnn_6_att_ff',
                    'n_out': 1,
                    'trainable': True,
                    'with_bias': True},
  'tdnn_6_att_ff': { 'activation': 'tanh',
                     'class': 'linear',
                     'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                     'from': 'concat_reconstruct_btn',
                     'n_out': 384,
                     'trainable': True,
                     'with_bias': True},
  'tdnn_6_att_mu': {'axes': 'except_batch', 'class': 'merge_dims', 'from': ['tdnn_6_att_weighted_x'], 'trainable': True},
  'tdnn_6_att_weighted_x': { 'auto_squeeze': False,
                             'base': 'concat_reconstruct_btn',
                             'class': 'generic_attention',
                             'trainable': True,
                             'weights': 'tdnn_6_att_weights'},
  'tdnn_6_att_weighted_x_2': { 'auto_squeeze': False,
                               'base': 'tdnn_6_squared',
                               'class': 'generic_attention',
                               'trainable': True,
                               'weights': 'tdnn_6_att_weights'},
  'tdnn_6_att_weighted_x_2_merged': {'axes': 'except_batch', 'class': 'merge_dims', 'from': ['tdnn_6_att_weighted_x_2'], 'trainable': True},
  'tdnn_6_att_weights': {'class': 'softmax_over_spatial', 'from': 'tdnn_6_att_e', 'trainable': True},
  'tdnn_6_avg': {'axes': 'T', 'class': 'reduce', 'from': 'concat_reconstruct_btn', 'mode': 'avg', 'trainable': True},
  'tdnn_6_squared': {'class': 'eval', 'eval': 'tf.math.square(source(0))', 'from': ['concat_reconstruct_btn'], 'trainable': True},
  'tdnn_7_ff': { 'activation': 'tanh',
                 'class': 'linear',
                 'forward_weights_init': {'class': 'VarianceScaling', 'distribution': 'uniform', 'mode': 'fan_in', 'scale': 0.78},
                 'from': 'tdnn_6',
                 'n_out': 512,
                 'trainable': True,
                 'with_bias': True}}
num_epochs = 600  # TODO
num_inputs = 50  # TODO
num_outputs = {'classes': [12001, 1], 'data': [50, 2], 'speaker_label': [2338, 1]}  # done
optimizer_epsilon = 1e-08  # done
save_interval = 1  # done
start_batch = 'auto'  # done
start_epoch = 'auto'  # done
stop_on_nonfinite_train_score = False  # done
target = 'classes'  # done
task = 'train'  # done
tf_log_memory_usage = True  # done
train = { 'class': 'MetaDataset',
  'data_map': {'classes': ('train_hdf', 'classes'), 'data': ('train_hdf', 'data'), 'speaker_label': ('speaker_label', 'data')},
  'datasets': { 'speaker_label': { 'class': 'HDFDataset',
                                   'files': ['/u/jxu/setups/librispeech/2022-09-06--conformer-librispeech/output/lbs_train_spk_label']},
                'train_hdf': { 'class': 'HDFDataset',
                               'files': [ '/work/asr3/luescher/hiwis/jxu/setups-data/librispeech/2022-09-06--conformer-librispeech/work/crnn/hdf/CRNNSprintDumpHDFJob.WUQsSgRoWRi3/output/data.hdf'],
                               'partition_epoch': 40,
                               'seq_ordering': 'random'}},
  'seq_order_control_dataset': 'train_hdf'}
truncation = -1  # done
update_on_device = True  # TODO?
use_spec_augment = False  # done
use_tensorflow = True  # done
window = 1  # done
config = {}

locals().update(**config)

import sys
sys.setrecursionlimit(3000)
